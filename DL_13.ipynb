{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb0cf7a-7f4b-46c0-b2b5-ffe2aa5b31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce235a78-4bcd-42e2-a05c-234c8d5d40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sentences for CBOW\n",
    "corpus = [\n",
    "    'I love natural language processing',\n",
    "    'Natural language processing is fun',\n",
    "    'I enjoy learning about machine learning',\n",
    "    'Deep learning is a subset of machine learning'\n",
    "]\n",
    "\n",
    "# Parameters\n",
    "window_size = 2  # Number of context words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced48d22-2f89-421f-a650-593193e3bfe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load pre-trained ResNet50 model + higher level layers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m ResNet50(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Freeze the base model layers to retain pre-trained features\u001b[39;00m\n\u001b[0;32m      5\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNet50' is not defined"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet50 model + higher level layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers to retain pre-trained features\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top for animal classification\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),      # Flatten the feature maps\n",
    "    layers.Dense(1024, activation='relu'), # Add a fully-connected layer\n",
    "    layers.Dropout(0.5),                  # Add dropout for regularization\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da5e3dc-a0d2-4956-b8d8-7611e7969077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Create CBOW training data\n",
    "def create_cbow_data(corpus, window_size):\n",
    "    X, y = [], []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for index, target in enumerate(words):\n",
    "            # Get context words\n",
    "            start_index = max(0, index - window_size)\n",
    "            end_index = min(len(words), index + window_size + 1)\n",
    "            context = [words[i] for i in range(start_index, end_index) if i != index]\n",
    "            X.append([word_index[w] for w in context])  # Convert context words to their index\n",
    "            y.append(word_index[target])  # Convert target word to its index\n",
    "    return X, y\n",
    "\n",
    "X, y = create_cbow_data(corpus, window_size)\n",
    "\n",
    "# Pad sequences for uniform input size\n",
    "X = pad_sequences(X, padding='post')\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b10d6e-7759-4f9b-861c-5e237447eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = len(word_index) + 1  # Add 1 for padding\n",
    "embedding_dim = 10  # Dimension of word embeddings\n",
    "\n",
    "# Build CBOW model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=X.shape[1]),\n",
    "    Flatten(),\n",
    "    Dense(vocab_size, activation='softmax')  # Output layer with softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e769e6-149d-468b-b010-0a0c10faaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14f82c-133d-4ca6-aaf2-955b22a0fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights of the embedding layer\n",
    "embeddings = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Print word embeddings\n",
    "for word, index in word_index.items():\n",
    "    print(f\"Word: {word}, Embedding: {embeddings[index]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
